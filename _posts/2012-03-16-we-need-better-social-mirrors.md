---
layout: post
title: We Need Better Social Mirrors
permalink: /blog/read/we-need-better-social-mirrors
---
A few weeks ago I tweeted: "Now that privacy is dead, maybe some of these big data companies can tell me who I am," and I wasn't kidding: I want to use the data that I'm generating for these companies to understand more about myself. The Information Diet makes the case that personalization in news does happen, and yes, filter bubbles exist but they're nothing new they've existed for as long as culture has. They're created by user choice -- filter bubbles are a reflection of the user's behavior and choices, not a corporate conspiracy to eliminate diverse opinions.

I don't subscribe to the notion that the only way to solve this problem is by designing better algorithms that give the user a more diverse information diet. Software's built by other human beings, and while I appreciate the idea that a little diversity ought to be injected into our diets via software, in that scenario the reader is simply ceding control over to a new kind of editor (a developer) rather than learning to make good decisions. It's a bit paternalistic to me.

Instead, I see the problem as a lack of a social mirror\[1\]. To go back to the aforementioned tweet: I wish the companies that are tasked with building up huge profiles of me and my behavior would allow me to tell me who I am better. To build for me a mirror of my social behavior online. Tell me that I only click on links from liberals on Facebook, or that I'm 25x more likely to click on pictures from my friends from Atlanta than I am my friends from San Francisco. Tell me the aggregate demographics of who I follow on twitter, and let me know whether or not I reply less on gmail to women than I do to men.

Right now we're playing without much of a social mirror. Sure, Google has its dashboard which gives you way to see much of the personal information Google has on you, as well as its ads preferences which tells you who the advertising part of Google thinks you are. The problem isn't just that they're inaccurate\[2\], it's that they aren't giving you an idea of consequence. Trying to keep a diverse social information diet without this mirror is like trying to shave without an actual mirror -- sure you can do it, but you're bound to miss some spots.\[3\]

Imagine how empowering a strong, well-polished social mirror would be: a census of your social activity. If you knew you hadn't emailed anybody in your family in 33 days, or that you were only clicking on links about entertainment news in Facebook perhaps you'd diversify your diet a little bit.

Combine this with knowing the rules of the personalization game, and we're on to something. In Eli Pariser's Filter Bubble Talk, he talks about not seeing links from his conservative friends anymore. But he doesn't see them because he doesn't click on them. What will expose Eli to more conservative ideas:

I think that the former will generate a lot of wasted space, and the latter. But if he's told that that kind of stuff isn't going to be headed his way anymore, fear of missing out will make Eli click on and read some conservative information. If he's checks on his Aunt Sally a lot more than he checks on his Uncle Warren, there's context to what's happening, and that's what's missing. A social mirror will produce the best outcome: knowledgeable corrective action and a more diverse information diet. Facebook knows how you spend time on Facebook. Google knows how you spend time on Google's wide swath of properties. It's about time they started sharing that information with you.

\[1\] Pete Skomoroch pointed this term out to me.

\[2\] Google thinks I am a 35 year old body builder interested in the arts and baby names that lives in Washington, DC. 2/5 are correct.

\[3\] I'm sorry for the metaphor that's generally only understandable by men, but I couldn't come up with something better. If there's something better, toss it in the comments.
